{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.assembly_graph\n",
    "\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "from math import sqrt, exp, prod, log, log1p\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {\n",
    "    'ACCCG': ['CCCGG'],\n",
    "    'CCCGG': ['CCGGT'],\n",
    "    'CCGGT': ['CGGTA'],\n",
    "    'CGGTA': ['GGTAC'],\n",
    "    'GGTAC': ['GTACC'],\n",
    "    'GTACC': ['TACCC'],\n",
    "    'TACCC': ['ACCCG'],\n",
    "}\n",
    "downstream, upstream = lib.assembly_graph.build_full_from_seed_graph(seed)\n",
    "\n",
    "observed_depth = lib.assembly_graph.add_reverse_complement_depth({\n",
    "    'ACCCG': 1,\n",
    "    'CCCGG': 1,\n",
    "    'CCGGT': 1,\n",
    "    'CGGTA': 1,\n",
    "    'GGTAC': 10,\n",
    "    'GTACC': 10,\n",
    "    'TACCC': 1,\n",
    "})\n",
    "\n",
    "assert lib.assembly_graph.mapping_all_upstream(upstream)\n",
    "upstream, observed_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to do this with matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "depth0 = pd.Series(observed_depth).astype(float)\n",
    "n = len(depth0)\n",
    "depth0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Directed\" graph with each node pointing to nodes that are downstream.\n",
    "# If I want a graph of each node pointing upstream, that's just dgraph.T\n",
    "# After the *first* step, where I distribute each nodes depth equally upstream\n",
    "# and downstream, I'm going to need two contingency tables, because\n",
    "# uflow != dflow.T\n",
    "\n",
    "linked_5p_to_3p = downstream\n",
    "\n",
    "dgraph_5p_to_3p = pd.DataFrame(np.zeros((n, n)), index=depth0.index, columns=depth0.index)\n",
    "for k in dgraph_5p_to_3p:\n",
    "    dgraph_5p_to_3p.loc[k, linked_5p_to_3p[k]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_contingency = dgraph_5p_to_3p.copy()\n",
    "r_contingency = dgraph_5p_to_3p.T.copy()\n",
    "\n",
    "sns.heatmap(l_contingency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "send_to_r = r_contingency\n",
    "send_to_l = l_contingency\n",
    "\n",
    "# This is not actually the flow,\n",
    "# because it's not proportional to depth...yet.\n",
    "\n",
    "depth = depth0\n",
    "\n",
    "total_from_l = send_to_r.sum()\n",
    "total_from_r = send_to_l.sum()\n",
    "\n",
    "# When it's not initialization\n",
    "# we'll update depth here.\n",
    "\n",
    "send_to_r_next = (send_to_l / total_from_r).multiply(depth, axis=1).T\n",
    "send_to_l_next = (send_to_r / total_from_l).multiply(depth, axis=1).T\n",
    "\n",
    "# Initialization done\n",
    "send_to_r = send_to_r_next\n",
    "send_to_l = send_to_l_next\n",
    "\n",
    "sns.heatmap(send_to_r)\n",
    "\n",
    "# table = pd.DataFrame(dict(depth=depth, in_degree_r=total_from_r, in_degree_l=total_from_l, out_degree_r=send_to_r.sum(1), out_degree_l=send_to_l.sum(1)))\n",
    "# table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Step\n",
    "total_from_l = send_to_r.sum()\n",
    "total_from_r = send_to_l.sum()\n",
    "\n",
    "gamma = 0\n",
    "\n",
    "# Update depth\n",
    "depth = (depth0 * gamma + depth + total_from_r + total_from_l) / (3 + gamma)\n",
    "# from_r_log1p = sp.special.log1p(total_from_r)\n",
    "# from_l_log1p = sp.special.log1p(total_from_l)\n",
    "# disagreement = np.abs(from_r_log1p - from_l_log1p)\n",
    "# suggestion = np.exp((from_r_log1p + from_l_log1p) / 2) - 1\n",
    "# weight = 1 / (2 + disagreement**2)\n",
    "# depth = (depth + suggestion * weight) / (1 + weight)\n",
    "\n",
    "send_to_r_next = (send_to_l / total_from_r).multiply(depth, axis=1).T\n",
    "send_to_l_next = (send_to_r / total_from_l).multiply(depth, axis=1).T\n",
    "\n",
    "send_to_r = send_to_r_next\n",
    "send_to_l = send_to_l_next\n",
    "\n",
    "# Step done\n",
    "\n",
    "sns.heatmap(send_to_l)\n",
    "# plt.plot(depth)\n",
    "# plt.ylim(0)\n",
    "\n",
    "# table = pd.DataFrame(dict(depth=depth, in_degree_r=total_from_r, in_degree_l=total_from_l, out_degree_r=send_to_r.sum(1), out_degree_l=send_to_l.sum(1)))\n",
    "# table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
