{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore graph-refined coverage estimation\n",
    "\n",
    "Coverage estimation for unitigs on an assembly graph\n",
    "is inherently noisy, due to the fact that sampling is finite.\n",
    "\n",
    "- Strategy for using assembly graph to improve binning of contigs\n",
    "    - Coverage estimates for contigs have a degree of noise, especially for short contigs.  Contigs that are adjacent on the assembly graph present additional information that could be incorporated into coverage estimates, the problem is that many splits represent strain-variation, so adjacent contigs may actually have very _different_ coverages.  One thing we expect is that \"true\" coverages should be conserved across branches, so that when an upstream single path splits into downstream two paths, the coverage of the two should sum to the coverage of the one.  Theoretically, this information should present an opportunity to improve empirical coverage estimates on the graph, thereby enabling binning of shorter contigs.\n",
    "- Proposed algorithm:\n",
    "    - Really this should be a pretty easy optimization problem to formulate...\n",
    "    - \"Latent\" coverage at a node is defined as the mean latent coverage of all neighbors (should be a reasonably quick matrix multiplication formulation for this...) plus some local perturbation; minimize both the magnitude of the perturbations as well as the difference between latent coverages and observed coverages\n",
    "    - Consider also fragmenting really long unitigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "Node labels\n",
    "\n",
    "```\n",
    "   \\             /\n",
    " (0)\\           /(3)\n",
    "     \\   (2)   /\n",
    "      ---------\n",
    "     /         \\\n",
    " (1)/           \\(4)\n",
    "   /             \\\n",
    "```\n",
    "\n",
    "\n",
    "Node \"expected\" coverages\n",
    "```\n",
    "   \\             /\n",
    "  x0\\           /x3\n",
    "     \\    x2   /\n",
    "      ---------\n",
    "     /         \\\n",
    "  x1/           \\x4\n",
    "   /             \\\n",
    "```\n",
    "\n",
    "Node coverage error (both true and observation error)\n",
    "```\n",
    "   \\             /\n",
    "  e0\\           /e3\n",
    "     \\    e2   /\n",
    "      ---------\n",
    "     /         \\\n",
    "  e1/           \\e4\n",
    "   /             \\\n",
    "```\n",
    "\n",
    "Node observed coverage\n",
    "```\n",
    "    \\             /\n",
    "x0+e0\\           /x3+e3\n",
    "      \\  x2+e2  /\n",
    "       ---------\n",
    "      /         \\\n",
    "x1+e0/           \\x4+e4\n",
    "    /             \\\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out this is a [Hidden Markov Random Field](https://en.wikipedia.org/wiki/Hidden_Markov_random_field)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two directed adjacency matrices\n",
    "\n",
    "# (E0) One point estimate for the true coverage\n",
    "# is the observed coverage.\n",
    "\n",
    "# A point estimate for the coverage \"from\"\n",
    "# a connected node on the left (equivilantly right)\n",
    "# is the coverage of that node minus the\n",
    "# coverage that _it_ shares with nodes to its right\n",
    "# (equivilantly left)\n",
    "\n",
    "# The expected coverage for each node is\n",
    "# the mean of the sum of the coverage \"from\"\n",
    "# nodes that connect on the left and the\n",
    "# sum \"from\" the right.\n",
    "\n",
    "# (E1) Another point estimate for the true\n",
    "# coverage is recursively defined as\n",
    "# the the mean of any other point estimates\n",
    "\n",
    "# (E2) Another point estimate for the true\n",
    "# coverage of each node is the weighted\n",
    "# mean of point estimates,\n",
    "# in particular point estimates obtained\n",
    "# from E0 and E1 above,\n",
    "# alternatively E0 and E2 (recursively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_col(x):\n",
    "    return np.nan_to_num(x / x.sum(0, keepdims=True))\n",
    "\n",
    "def norm_row(x):\n",
    "    return np.nan_to_num(x / x.sum(1, keepdims=True))\n",
    "\n",
    "def contrib_from_side(x, a):\n",
    "    return np.where(a.sum(1) != 0,\n",
    "                    (norm_col(a * x.T) @ x.T).flatten(),\n",
    "                    np.nan)\n",
    "\n",
    "def contrib_from_neighbors(x, left, right):\n",
    "    from_left = contrib_from_side(x, left)\n",
    "    from_right = contrib_from_side(x, right)\n",
    "    \n",
    "    # Fill NAs with the other side so that means\n",
    "    # will only reflect the connected sides.\n",
    "    from_left = np.where(~np.isnan(from_left),\n",
    "                         from_left, from_right)\n",
    "    from_right = np.where(~np.isnan(from_right),\n",
    "                          from_right, from_left)\n",
    "    \n",
    "    return (from_left + from_right) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes that connect on the left.\n",
    "L = np.array([\n",
    "#    0  1  2  3  4\n",
    "    [0, 0, 0, 0, 0],  # 0\n",
    "    [0, 0, 0, 0, 0],  # 1\n",
    "    [1, 1, 0, 0, 0],  # 2\n",
    "    [0, 0, 1, 0, 0],  # 3\n",
    "    [0, 0, 1, 0, 0],  # 4\n",
    "])\n",
    "\n",
    "# Nodes that connect on the right\n",
    "R = np.array([\n",
    "#    0  1  2  3  4\n",
    "    [0, 0, 1, 0, 0],  # 0\n",
    "    [0, 0, 1, 0, 0],  # 1\n",
    "    [0, 0, 0, 1, 1],  # 2\n",
    "    [0, 0, 0, 0, 0],  # 3\n",
    "    [0, 0, 0, 0, 0],  # 4\n",
    "])\n",
    "\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Initial coverage point estimates (e.g. from observed coverage)\n",
    "y_obs = np.array([[2.0, 0.5, 2.0, 1.0, 3.0]])\n",
    "\n",
    "# How heavily does each nodes observed coverage affect its\n",
    "# estimate versus the effect of its neighbors.\n",
    "# Should be between 0 and 1\n",
    "# (?) How to convert unitig length to a value\n",
    "# between 0 and 1?  It's obvious that\n",
    "# it should be saturating with length,\n",
    "# but probably not to 1.0\n",
    "# since there's always coverage noise even with really long\n",
    "# contigs.\n",
    "obs_weight = np.array([0.25, 0.25, 0.75, 0.25, 0.5])\n",
    "y_iter = y_obs\n",
    "for i in range(100):\n",
    "    y_next = ((obs_weight * y_obs)\n",
    "              + ((1 - obs_weight)\n",
    "                 * (learning_rate * contrib_from_neighbors(y_iter, L, R)\n",
    "                    + (1 - learning_rate) * y_iter)))\n",
    "    delta = y_next - y_iter\n",
    "    y_iter = y_next\n",
    "print(y_iter, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage point estimates.\n",
    "Y_itr = np.array([1.5, 1.0, 2.0, 1.0, 3.0])\n",
    "\n",
    "\n",
    "# Neighbor-based point estimates\n",
    "def calculate_Y_nbr(x, L, R):\n",
    "    return (((L @ x) + (R @ x)) / 2)\n",
    "\n",
    "\n",
    "# Initial\n",
    "print(Y_itr)\n",
    "\n",
    "def step_Y_itr(x, L, R):\n",
    "    X_nbr = calculate_Y_nbr(x, L, R)\n",
    "    return 0.5 * x + 0.5 * x_nbr\n",
    "\n",
    "# Iterate\n",
    "Y_itr = step_Y_itr(Y_itr, L, R)\n",
    "print(Y_itr)\n",
    "\n",
    "# Iterate\n",
    "Y_itr = step_Y_itr(Y_itr, L, R)\n",
    "print(Y_itr)\n",
    "\n",
    "# Iterate\n",
    "Y_itr = step_Y_itr(Y_itr, L, R)\n",
    "print(Y_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed coverages on each node.\n",
    "#             0  1  2  3  4\n",
    "X = np.array([1, 1, 2, 1, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}