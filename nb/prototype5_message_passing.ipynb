{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.assembly_graph\n",
    "import lib.plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sparse\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure out why a (n, n) sparse dmatrix times a (n,) depth vector produces an (n, 1) result\n",
    "# This doesn't seem to happen for dense matrices\n",
    "\n",
    "n = 5\n",
    "\n",
    "# Dense\n",
    "eye = np.eye(n, k=1) # Offset diagonal of 1's\n",
    "rng = np.arange(n)\n",
    "# print(eye * rng)                     # Multiplies vector along the bottom \n",
    "# print(rng * eye)                     # Multiplies vector along the bottom \n",
    "# print(eye * np.expand_dims(rng, 0))  # Multiplies vector along the bottom\n",
    "# print(eye * np.expand_dims(rng, 1))  # Multiplies vector along the side\n",
    "\n",
    "# Sparse rng and sparse eye\n",
    "eye = sp.sparse.csr_matrix(np.eye(n, k=1))\n",
    "rng = sp.sparse.csr_matrix(np.arange(n))\n",
    "rng_diag = sp.sparse.diags(np.arange(n), format='dia')  # = rng.multiply(sp.sparse.eye(n))\n",
    "# print(eye * rng)                     # \"ValueError: dimension mismatch\"\n",
    "print((rng * eye).toarray())           # (1, n) row vector?? No idea what's going on here.\n",
    "print(eye.multiply(rng).toarray())     # Multiplies rng vector along the bottom\n",
    "print(rng.multiply(eye).toarray())     # Multiplies rng vector along the bottom\n",
    "print(eye.T.multiply(rng).T.toarray())     # Multiplies rng vector along the side\n",
    "print((rng_diag * eye).toarray())     # Multiplies rng vector along the side\n",
    "print((eye * rng_diag).toarray())     # Multiplies rng vector along the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure out why a (n, n) sparse dmatrix times a (n,) depth vector produces an (n, 1) result\n",
    "# This doesn't seem to happen for dense matrices\n",
    "\n",
    "n = 5\n",
    "\n",
    "# Dense\n",
    "eye = np.eye(n, k=1) # Offset diagonal of 1's\n",
    "rng = np.arange(n)\n",
    "# print(eye * rng)                     # Multiplies vector along the bottom \n",
    "# print(rng * eye)                     # Multiplies vector along the bottom \n",
    "# print(eye * np.expand_dims(rng, 0))  # Multiplies vector along the bottom\n",
    "# print(eye * np.expand_dims(rng, 1))  # Multiplies vector along the side\n",
    "\n",
    "# Sparse sparse eye and dense rng\n",
    "eye = sparse.COO.from_numpy(np.eye(n, k=1))\n",
    "rng = np.arange(n)\n",
    "# rng_diag = sp.sparse.diags(np.arange(n), format='dia')  # = rng.multiply(sp.sparse.eye(n))\n",
    "print((eye * rng).todense())           # Multiplies rng vector along the bottom\n",
    "print((rng * eye).todense())           # Multiplies rng vector along the bottom\n",
    "print((eye * rng.reshape((n, 1))).todense())           # Multiplies rng vector along the side\n",
    "print((np.multiply(eye.T, rng)).T.todense())           # Multiplies rng vector along the side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sequence(n):\n",
    "    sequence = ''.join(np.random.choice(['A', 'C', 'G', 'T'], size=n))\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def collect_kmers(sequences):\n",
    "    all_kmers = set()\n",
    "    \n",
    "    for seq in sequences:\n",
    "        for i in range(len(seq) - k):\n",
    "            kmer = seq[i: i + k]\n",
    "            if kmer not in all_kmers:\n",
    "                kmer_rc = lib.assembly_graph.reverse_complement(kmer)\n",
    "                all_kmers |= set([kmer, kmer_rc])\n",
    "\n",
    "    return all_kmers\n",
    "\n",
    "\n",
    "def build_seed_from_one_sequence(sequence, k):\n",
    "    # Build graph and simulate depths\n",
    "    seed = defaultdict(set)\n",
    "    last_kmer = sequence[:k]\n",
    "    for i in range(1, len(sequence) - k):\n",
    "        kmer = sequence[i: i + k]\n",
    "        seed[last_kmer].add(kmer)\n",
    "        last_kmer = kmer\n",
    "        \n",
    "    return seed\n",
    "\n",
    "\n",
    "def all_nodes(links):\n",
    "    return set(links.keys()) | set(chain.from_iterable(links.values()))\n",
    "\n",
    "\n",
    "def build_depth_from_seed(seed, depth_fn):\n",
    "    nodes = all_nodes(seed)\n",
    "    depth = defaultdict(lambda: 0)\n",
    "    depth.update({unitig: depth_fn(unitig) for unitig in nodes})\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_depth(r, l, d, weight):\n",
    "    # TODO: Confirm that this broadcasts correctly\n",
    "    return (r + l + weight * d) / (2 + weight)\n",
    "\n",
    "def nan_to_num(x, value=0):\n",
    "    return np.where(np.isnan(x), 0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.sparse.coo_matrix.tocsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_coo_dgraph_from_seed(seed, depth):\n",
    "    right, left = lib.assembly_graph.build_full_from_seed_graph(seed)\n",
    "    depth = pd.Series(lib.assembly_graph.add_reverse_complement_depth(depth)).astype(float)\n",
    "    \n",
    "    nodes = all_nodes(right)\n",
    "    idx = pd.Series(depth.index, name='unitig').reset_index().set_index('unitig').squeeze()\n",
    "    assert (depth.index.isin(right.keys()) | depth.index.isin(left.keys())).all()\n",
    "    items = []\n",
    "    for l in depth.index:\n",
    "        i = idx[l]\n",
    "        for r in right[l]:\n",
    "            j = idx[r]\n",
    "            items.append(((i, j), 1))\n",
    "    dgraph = sparse.COO.from_iter(items, shape=(len(idx), len(idx)))\n",
    "    return dgraph, depth.values, idx.index\n",
    "\n",
    "def build_csr_dgraph_from_seed(seed, depth):\n",
    "    right, left = lib.assembly_graph.build_full_from_seed_graph(seed)\n",
    "    depth = pd.Series(lib.assembly_graph.add_reverse_complement_depth(depth)).astype(float)\n",
    "    \n",
    "    nodes = all_nodes(right)\n",
    "    idx = pd.Series(depth.index, name='unitig').reset_index().set_index('unitig').squeeze()\n",
    "    assert (depth.index.isin(right.keys()) | depth.index.isin(left.keys())).all()\n",
    "    ii, jj = [], []\n",
    "    for l in depth.index:\n",
    "        for r in right[l]:\n",
    "            ii.append(idx[l])\n",
    "            jj.append(idx[r])\n",
    "    dgraph = sp.sparse.coo_matrix((np.ones_like(ii), (ii, jj)), shape=(len(idx), len(idx))).tocsr()\n",
    "    return dgraph, depth.values, idx.index\n",
    "\n",
    "\n",
    "def build_dgraph_from_seed(seed, depth):\n",
    "    right, left = lib.assembly_graph.build_full_from_seed_graph(seed)\n",
    "    depth = pd.Series(lib.assembly_graph.add_reverse_complement_depth(depth)).astype(float)\n",
    "    \n",
    "    nodes = all_nodes(right)\n",
    "    idx = pd.Series(depth.index, name='unitig').reset_index().set_index('unitig').squeeze()\n",
    "    assert (depth.index.isin(right.keys()) | depth.index.isin(left.keys())).all()\n",
    "    items = []\n",
    "    for l in depth.index:\n",
    "        i = idx[l]\n",
    "        for r in right[l]:\n",
    "            j = idx[r]\n",
    "            items.append(((i, j), 1))\n",
    "    dgraph = sparse.COO.from_iter(items, shape=(len(idx), len(idx)))\n",
    "    return dgraph.todense(), depth.values, idx.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_messages(dgraph, depth):\n",
    "    # Step -1\n",
    "    send_to_r = dgraph\n",
    "    send_to_l = dgraph.T\n",
    "    print(type(send_to_r))\n",
    "    total_from_l = send_to_r.sum(0)\n",
    "    total_from_r = send_to_l.sum(0)\n",
    "    proportions_r = nan_to_num(send_to_l / total_from_r)\n",
    "    proportions_l = nan_to_num(send_to_r / total_from_l)\n",
    "    send_to_r_next = (np.multiply(depth, proportions_r)).T\n",
    "    send_to_l_next = (np.multiply(depth, proportions_l)).T\n",
    "    send_to_r = send_to_r_next\n",
    "    send_to_l = send_to_l_next\n",
    "    print(type(send_to_r))\n",
    "\n",
    "    # Step 0\n",
    "    total_from_l = send_to_r.sum(0)\n",
    "    total_from_r = send_to_l.sum(0)\n",
    "    proportions_r = nan_to_num(send_to_l / total_from_r)\n",
    "    proportions_l = nan_to_num(send_to_r / total_from_l)\n",
    "    send_to_r_next = (np.multiply(depth, proportions_r)).T\n",
    "    send_to_l_next = (np.multiply(depth, proportions_l)).T\n",
    "    send_to_r = send_to_r_next\n",
    "    send_to_l = send_to_l_next\n",
    "\n",
    "    return send_to_r, send_to_l\n",
    "\n",
    "def iterate_messages(\n",
    "    send_to_r,\n",
    "    send_to_l,\n",
    "    depth,\n",
    "    new_depth_fn=mean_depth,\n",
    "    weight=1.0,\n",
    "):\n",
    "    total_from_l = send_to_r.sum(0)\n",
    "    total_from_r = send_to_l.sum(0)\n",
    "    # Update depth\n",
    "    next_depth = new_depth_fn(total_from_r, total_from_l, depth, weight)\n",
    "    # Scale the depth so there's no overall loss.\n",
    "    depth = next_depth * (depth.sum() / next_depth.sum())\n",
    "    # Calculate next message\n",
    "    proportions_r = nan_to_num(send_to_l / total_from_r)\n",
    "    proportions_l = nan_to_num(send_to_r / total_from_l)\n",
    "    send_to_r_next = (np.multiply(depth, proportions_r)).T\n",
    "    send_to_l_next = (np.multiply(depth, proportions_l)).T\n",
    "    send_to_r = send_to_r_next\n",
    "    send_to_l = send_to_l_next\n",
    "    return send_to_r, send_to_l, depth\n",
    "\n",
    "def initialize_messages_sparse(dgraph, depth):\n",
    "    # Step -1\n",
    "    send_to_r = dgraph\n",
    "    send_to_l = dgraph.T\n",
    "    print(type(send_to_r))\n",
    "    total_from_l = send_to_r.sum(0)\n",
    "    total_from_r = send_to_l.sum(0)\n",
    "    proportions_r = nan_to_num(send_to_l / total_from_r)\n",
    "    proportions_l = nan_to_num(send_to_r / total_from_l)\n",
    "    send_to_r_next = (depth.multiply(proportions_r)).T\n",
    "    send_to_l_next = (depth.multiply(proportions_l)).T\n",
    "    send_to_r = send_to_r_next\n",
    "    send_to_l = send_to_l_next\n",
    "    print(type(send_to_r))\n",
    "\n",
    "    # Step 0\n",
    "    total_from_l = send_to_r.sum(0)\n",
    "    total_from_r = send_to_l.sum(0)\n",
    "    proportions_r = nan_to_num(send_to_l / total_from_r)\n",
    "    proportions_l = nan_to_num(send_to_r / total_from_l)\n",
    "    send_to_r_next = (depth.multiply(proportions_r)).T\n",
    "    send_to_l_next = (depth.multiply(proportions_l)).T\n",
    "    send_to_r = send_to_r_next\n",
    "    send_to_l = send_to_l_next\n",
    "\n",
    "    return send_to_r, send_to_l\n",
    "\n",
    "def iterate_messages_sparse(\n",
    "    send_to_r,\n",
    "    send_to_l,\n",
    "    depth,\n",
    "    new_depth_fn=mean_depth,\n",
    "    weight=1.0,\n",
    "):\n",
    "    total_from_l = send_to_r.sum(0)\n",
    "    total_from_r = send_to_l.sum(0)\n",
    "    # Update depth\n",
    "    next_depth = new_depth_fn(total_from_r, total_from_l, depth, weight)\n",
    "    # Scale the depth so there's no overall loss.\n",
    "    depth = next_depth * (depth.sum() / next_depth.sum())\n",
    "    # Calculate next message\n",
    "    proportions_r = nan_to_num(send_to_l / total_from_r)\n",
    "    proportions_l = nan_to_num(send_to_r / total_from_l)\n",
    "    send_to_r_next = (np.multiply(depth, proportions_r)).T\n",
    "    send_to_l_next = (np.multiply(depth, proportions_l)).T\n",
    "    send_to_r = send_to_r_next\n",
    "    send_to_l = send_to_l_next\n",
    "    return send_to_r, send_to_l, depth\n",
    "\n",
    "\n",
    "def run_message_passing_sparse(seed, observed_depth, thresh=1e-3):\n",
    "    dgraph, depth0, idx = build_csr_dgraph_from_seed(seed, observed_depth)\n",
    "    send_to_r, send_to_l = initialize_messages_sparse(dgraph, depth0)\n",
    "\n",
    "    depth = depth0\n",
    "    tbar = tqdm(position=0, leave=True)\n",
    "    while True:\n",
    "        send_to_r, send_to_l, new_depth = iterate_messages_sparse(\n",
    "            send_to_r, send_to_l, depth, new_depth_fn=mean_depth,\n",
    "        )\n",
    "        delta = new_depth - depth\n",
    "        change = np.sqrt(np.sum(np.square(new_depth - depth)))\n",
    "        depth = new_depth\n",
    "        tbar.update()\n",
    "        tbar.set_postfix({'change': change})\n",
    "        if change < thresh:\n",
    "            print(\"CONVERGED\")\n",
    "            break\n",
    "    # Recover labels\n",
    "    send_to_r, send_to_l = [pd.DataFrame(send.todense(), index=idx, columns=idx) for send in [send_to_r, send_to_l]]\n",
    "    depth = pd.Series(depth, index=idx)\n",
    "    depth0 = pd.Series(depth0, index=idx)\n",
    "    return depth, send_to_r, send_to_l, depth0\n",
    "\n",
    "def run_message_passing(seed, observed_depth, thresh=1e-3):\n",
    "    dgraph, depth0, idx = build_dgraph_from_seed(seed, observed_depth)\n",
    "    send_to_r, send_to_l = initialize_messages(dgraph, depth0)\n",
    "\n",
    "    depth = depth0\n",
    "    tbar = tqdm(position=0, leave=True)\n",
    "    while True:\n",
    "        send_to_r, send_to_l, new_depth = iterate_messages(\n",
    "            send_to_r, send_to_l, depth, new_depth_fn=mean_depth,\n",
    "        )\n",
    "        delta = new_depth - depth\n",
    "        change = np.sqrt(np.sum(np.square(new_depth - depth)))\n",
    "        depth = new_depth\n",
    "        tbar.update()\n",
    "        tbar.set_postfix({'change': change})\n",
    "        if change < thresh:\n",
    "            print(\"CONVERGED\")\n",
    "            break\n",
    "    # Recover labels\n",
    "    send_to_r, send_to_l = [pd.DataFrame(send, index=idx, columns=idx) for send in [send_to_r, send_to_l]]\n",
    "    depth = pd.Series(depth, index=idx)\n",
    "    depth0 = pd.Series(depth0, index=idx)\n",
    "    return depth, send_to_r, send_to_l, depth0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate sequence\n",
    "np.random.seed(1)\n",
    "sequence = simulate_sequence(int(1e5))\n",
    "\n",
    "seed = build_seed_from_one_sequence(sequence, 5)\n",
    "\n",
    "# Simulate depth\n",
    "depth_fn = lambda kmer: np.exp(np.random.randn() * 2)\n",
    "observed_depth = build_depth_from_seed(seed, depth_fn)\n",
    "\n",
    "depth, send_to_r, send_to_l, depth0 = run_message_passing(seed, observed_depth, thresh=1e-4)\n",
    "depth_table = pd.DataFrame(dict(old_depth=depth0, new_depth=depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 200)\n",
    "plt.hist(depth_table, bins=bins, alpha=0.5, histtype='stepfilled')\n",
    "# plt.hist(depth, bins=bins, alpha=0.7)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tall saw-horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {\n",
    "    'AACCG': ['ACCGG'],\n",
    "    'ACCGG': ['CCGGG', 'CCGGA'],\n",
    "    'TACCG': ['ACCGG'],\n",
    "    'TAACC': ['AACCG'],\n",
    "    'TTACC': ['TACCG'],\n",
    "    'CCGGG': ['CGGGT'],\n",
    "    'CCGGA': ['CGGAT'],\n",
    "}\n",
    "observed_depth = lib.assembly_graph.add_reverse_complement_depth({\n",
    "    'AACCG': 9,\n",
    "    'ACCGG': 10,\n",
    "    'CCGGG': 9,\n",
    "    'CCGGA': 1,\n",
    "    'TACCG': 1,\n",
    "    'TAACC': 9,\n",
    "    'TTACC': 1,\n",
    "    'CGGGT': 9,\n",
    "    'CGGAT': 1,\n",
    "})\n",
    "\n",
    "depth, send_to_r, send_to_l, depth0 = run_message_passing(seed, observed_depth)\n",
    "sns.heatmap(send_to_r + send_to_l)\n",
    "pd.DataFrame(dict(old_depth=depth0, new_depth=depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {\n",
    "    'AACCG': ['ACCGG'],\n",
    "    'ACCGG': ['CCGGG', 'CCGGA'],\n",
    "    'TACCG': ['ACCGG'],\n",
    "}\n",
    "observed_depth = lib.assembly_graph.add_reverse_complement_depth({\n",
    "    'AACCG': 3,\n",
    "    'ACCGG': 4,\n",
    "    'CCGGG': 3,\n",
    "    'CCGGA': 1,\n",
    "    'TACCG': 1,\n",
    "})\n",
    "\n",
    "depth, send_to_r, send_to_l, depth0 = run_message_passing(seed, observed_depth)\n",
    "sns.heatmap(send_to_r + send_to_l)\n",
    "pd.DataFrame(dict(old_depth=depth0, new_depth=depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saw-horse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle w/ Switch-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {\n",
    "    'ACCCG': ['CCCGG'],\n",
    "    'CCCGG': ['CCGGT'],\n",
    "    'CCGGT': ['CGGTA'],\n",
    "    'CGGTA': ['GGTAC'],\n",
    "    'GGTAC': ['GTACC'],\n",
    "    'GTACC': ['TACCC'],\n",
    "    'TACCC': ['ACCCG'],\n",
    "}\n",
    "observed_depth = lib.assembly_graph.add_reverse_complement_depth({\n",
    "    'ACCCG': 1,\n",
    "    'CCCGG': 1,\n",
    "    'CCGGT': 1,\n",
    "    'CGGTA': 1,\n",
    "    'GGTAC': 1,\n",
    "    'GTACC': 1,\n",
    "    'TACCC': 1,\n",
    "})\n",
    "\n",
    "depth, send_to_r, send_to_l, depth0 = run_message_passing(seed, observed_depth)\n",
    "sns.heatmap(send_to_r + send_to_l)\n",
    "pd.DataFrame(dict(old_depth=depth0, new_depth=depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Six-Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {\n",
    "    'ACCCG': ['CCCGG'],\n",
    "    'CCCGG': ['CCGGA'],\n",
    "    'CCGGA': ['CGGAC'],\n",
    "    'CGGAC': ['GGACC'],\n",
    "    'GGACC': ['GACCC'],\n",
    "    'GACCC': ['ACCCG']\n",
    "}\n",
    "observed_depth = lib.assembly_graph.add_reverse_complement_depth({\n",
    "    'ACCCG': 1,\n",
    "    'CCCGG': 1,\n",
    "    'CCGGA': 2,\n",
    "    'CGGAC': 1,\n",
    "    'GGACC': 1,\n",
    "    'GACCC': 1,\n",
    "})\n",
    "\n",
    "depth, send_to_r, send_to_l, depth0 = run_message_passing(seed, observed_depth)\n",
    "sns.heatmap(send_to_r + send_to_l)\n",
    "pd.DataFrame(dict(old_depth=depth0, new_depth=depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Six-cycle w/ Spur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {\n",
    "    'ACCCG': ['CCCGG'],\n",
    "    'CCCGG': ['CCGGA', 'CCGGC'],\n",
    "    'CCGGA': ['CGGAC'],\n",
    "    'CGGAC': ['GGACC'],\n",
    "    'GGACC': ['GACCC'],\n",
    "    'GACCC': ['ACCCG']\n",
    "}\n",
    "observed_depth = lib.assembly_graph.add_reverse_complement_depth({\n",
    "    'ACCCG': 1,\n",
    "    'CCCGG': 1,\n",
    "    'CCGGA': 1,\n",
    "    'CGGAC': 1,\n",
    "    'GGACC': 1,\n",
    "    'GACCC': 1,\n",
    "    'CCGGC': 1,\n",
    "})\n",
    "\n",
    "depth, send_to_r, send_to_l, depth0 = run_message_passing(seed, observed_depth)\n",
    "sns.heatmap(send_to_r + send_to_l)\n",
    "pd.DataFrame(dict(old_depth=depth0, new_depth=depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double-six-cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {\n",
    "    # Top cycle\n",
    "    'GGACC': ['GACCC'],\n",
    "    'GACCC': ['ACCCG'],\n",
    "    'ACCCG': ['CCCGG'],\n",
    "    'CCCGG': ['CCGGA'],\n",
    "    'CCGGA': ['CGGAC'],\n",
    "    \n",
    "    # Link\n",
    "    'CGGAC': ['GGACC', 'GGACT'],\n",
    "    \n",
    "    # Bottom cycle\n",
    "    'GGACT': ['GACTC'],\n",
    "    'GACTC': ['ACTCG'],\n",
    "    'ACTCG': ['CTCGG'],\n",
    "    'CTCGG': ['TCGGA'],\n",
    "    'TCGGA': ['CGGAC'],\n",
    "    \n",
    "}\n",
    "observed_depth = lib.assembly_graph.add_reverse_complement_depth({\n",
    "    # Top cycle\n",
    "    'GGACC': 1,\n",
    "    'GACCC': 1,\n",
    "    'ACCCG': 1,\n",
    "    'CCCGG': 1,\n",
    "    'CCGGA': 1,\n",
    "    \n",
    "    # Link\n",
    "    'CGGAC': 3,\n",
    "    \n",
    "    # Bottom \n",
    "    'GGACT': 2, \n",
    "    'GACTC': 2,\n",
    "    'ACTCG': 2,\n",
    "    'CTCGG': 2,\n",
    "    'TCGGA': 2,\n",
    "})\n",
    "\n",
    "depth, send_to_r, send_to_l, depth0 = run_message_passing(seed, observed_depth)\n",
    "sns.heatmap(send_to_r + send_to_l)\n",
    "pd.DataFrame(dict(old_depth=depth0, new_depth=depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lonely-stick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {\n",
    "    # Top cycle\n",
    "    'GGACC': ['GACCT'],\n",
    "}\n",
    "observed_depth = lib.assembly_graph.add_reverse_complement_depth({\n",
    "    # Top cycle\n",
    "    'GGACC': 1,\n",
    "    'GACCT': 2,\n",
    "})\n",
    "\n",
    "depth, send_to_r, send_to_l, depth0 = run_message_passing(seed, observed_depth)\n",
    "sns.heatmap(send_to_r + send_to_l)\n",
    "pd.DataFrame(dict(old_depth=depth0, new_depth=depth))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}